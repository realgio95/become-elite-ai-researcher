{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Concatenating Tensors: cat and stack\n",
        "\n",
        "Combine multiple tensors together!\n",
        "cat concatenates along existing dimension, stack creates new dimension.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. cat: Concatenate Along Dimension\n",
        "\n",
        "torch.cat() concatenates tensors along an existing dimension!\n",
        "Tensors must have matching shapes except along the concatenation dimension.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor t1:\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "Shape: torch.Size([2, 2])\n",
            "\n",
            "Tensor t2:\n",
            "tensor([[5., 6.],\n",
            "        [7., 8.]])\n",
            "Shape: torch.Size([2, 2])\n",
            "\n",
            "torch.cat([t1, t2], dim=0) - concatenate along rows:\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.],\n",
            "        [7., 8.]])\n",
            "Shape: torch.Size([4, 2])\n",
            "\n",
            "torch.cat([t1, t2], dim=1) - concatenate along columns:\n",
            "tensor([[1., 2., 5., 6.],\n",
            "        [3., 4., 7., 8.]])\n",
            "Shape: torch.Size([2, 4])\n",
            "\n",
            "Concatenate 3 tensors:\n",
            "tensor([[ 1.,  2.],\n",
            "        [ 3.,  4.],\n",
            "        [ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.],\n",
            "        [11., 12.]])\n",
            "Shape: torch.Size([6, 2])\n"
          ]
        }
      ],
      "source": [
        "# Create two tensors\n",
        "t1 = torch.tensor([[1, 2], \n",
        "                   [3, 4]], dtype=torch.float32)\n",
        "\n",
        "t2 = torch.tensor([[5, 6], \n",
        "                   [7, 8]], dtype=torch.float32)\n",
        "\n",
        "print(\"Tensor t1:\")\n",
        "print(t1)\n",
        "print(f\"Shape: {t1.shape}\")\n",
        "print()\n",
        "\n",
        "print(\"Tensor t2:\")\n",
        "print(t2)\n",
        "print(f\"Shape: {t2.shape}\")\n",
        "print()\n",
        "\n",
        "# Concatenate along dimension 0 (stack vertically)\n",
        "t_cat0 = torch.cat([t1, t2], dim=0)\n",
        "print(\"torch.cat([t1, t2], dim=0) - concatenate along rows:\")\n",
        "print(t_cat0)\n",
        "print(f\"Shape: {t_cat0.shape}\")\n",
        "print()\n",
        "\n",
        "# Concatenate along dimension 1 (stack horizontally)\n",
        "t_cat1 = torch.cat([t1, t2], dim=1)\n",
        "print(\"torch.cat([t1, t2], dim=1) - concatenate along columns:\")\n",
        "print(t_cat1)\n",
        "print(f\"Shape: {t_cat1.shape}\")\n",
        "print()\n",
        "\n",
        "# Concatenate multiple tensors\n",
        "t3 = torch.tensor([[9, 10], \n",
        "                   [11, 12]], dtype=torch.float32)\n",
        "t_cat_multiple = torch.cat([t1, t2, t3], dim=0)\n",
        "print(\"Concatenate 3 tensors:\")\n",
        "print(t_cat_multiple)\n",
        "print(f\"Shape: {t_cat_multiple.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. stack: Stack Along New Dimension\n",
        "\n",
        "torch.stack() creates a new dimension and stacks tensors!\n",
        "All tensors must have the same shape.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor t1:\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "Shape: torch.Size([2, 2])\n",
            "\n",
            "Tensor t2:\n",
            "tensor([[5., 6.],\n",
            "        [7., 8.]])\n",
            "Shape: torch.Size([2, 2])\n",
            "\n",
            "torch.stack([t1, t2], dim=0):\n",
            "tensor([[[1., 2.],\n",
            "         [3., 4.]],\n",
            "\n",
            "        [[5., 6.],\n",
            "         [7., 8.]]])\n",
            "Shape: torch.Size([2, 2, 2])\n",
            "(New dimension 0 created!)\n",
            "\n",
            "torch.stack([t1, t2], dim=1):\n",
            "tensor([[[1., 2.],\n",
            "         [5., 6.]],\n",
            "\n",
            "        [[3., 4.],\n",
            "         [7., 8.]]])\n",
            "Shape: torch.Size([2, 2, 2])\n",
            "\n",
            "torch.stack([t1, t2], dim=2):\n",
            "tensor([[[1., 5.],\n",
            "         [2., 6.]],\n",
            "\n",
            "        [[3., 7.],\n",
            "         [4., 8.]]])\n",
            "Shape: torch.Size([2, 2, 2])\n",
            "\n",
            "============================================================\n",
            "COMPARISON: cat vs stack\n",
            "============================================================\n",
            "cat: Concatenates along existing dimension\n",
            "  cat shape: torch.Size([4, 2])\n",
            "\n",
            "stack: Creates new dimension and stacks\n",
            "  stack shape: torch.Size([2, 2, 2])\n",
            "\n",
            "Difference: stack adds a new dimension!\n"
          ]
        }
      ],
      "source": [
        "# Create two tensors\n",
        "t1 = torch.tensor([[1, 2], \n",
        "                   [3, 4]], dtype=torch.float32)\n",
        "\n",
        "t2 = torch.tensor([[5, 6], \n",
        "                   [7, 8]], dtype=torch.float32)\n",
        "\n",
        "print(\"Tensor t1:\")\n",
        "print(t1)\n",
        "print(f\"Shape: {t1.shape}\")\n",
        "print()\n",
        "\n",
        "print(\"Tensor t2:\")\n",
        "print(t2)\n",
        "print(f\"Shape: {t2.shape}\")\n",
        "print()\n",
        "\n",
        "# Stack along dimension 0 (new first dimension)\n",
        "t_stack0 = torch.stack([t1, t2], dim=0)\n",
        "print(\"torch.stack([t1, t2], dim=0):\")\n",
        "print(t_stack0)\n",
        "print(f\"Shape: {t_stack0.shape}\")\n",
        "print(\"(New dimension 0 created!)\")\n",
        "print()\n",
        "\n",
        "# Stack along dimension 1\n",
        "t_stack1 = torch.stack([t1, t2], dim=1)\n",
        "print(\"torch.stack([t1, t2], dim=1):\")\n",
        "print(t_stack1)\n",
        "print(f\"Shape: {t_stack1.shape}\")\n",
        "print()\n",
        "\n",
        "# Stack along dimension 2\n",
        "t_stack2 = torch.stack([t1, t2], dim=2)\n",
        "print(\"torch.stack([t1, t2], dim=2):\")\n",
        "print(t_stack2)\n",
        "print(f\"Shape: {t_stack2.shape}\")\n",
        "print()\n",
        "\n",
        "# Compare: cat vs stack\n",
        "print(\"=\" * 60)\n",
        "print(\"COMPARISON: cat vs stack\")\n",
        "print(\"=\" * 60)\n",
        "print(\"cat: Concatenates along existing dimension\")\n",
        "print(f\"  cat shape: {torch.cat([t1, t2], dim=0).shape}\")\n",
        "print()\n",
        "print(\"stack: Creates new dimension and stacks\")\n",
        "print(f\"  stack shape: {torch.stack([t1, t2], dim=0).shape}\")\n",
        "print()\n",
        "print(\"Difference: stack adds a new dimension!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature vectors:\n",
            "feature1: tensor([1., 2., 3.])\n",
            "feature2: tensor([4., 5., 6.])\n",
            "feature3: tensor([7., 8., 9.])\n",
            "\n",
            "Stacked into batch:\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.],\n",
            "        [7., 8., 9.]])\n",
            "Shape: torch.Size([3, 3])  (batch_size=3, features=3)\n",
            "\n",
            "Layer outputs:\n",
            "layer1 shape: torch.Size([2, 3])\n",
            "layer2 shape: torch.Size([2, 3])\n",
            "\n",
            "Concatenated features:\n",
            "tensor([[ 0.6867, -1.2070, -0.4014,  0.2215, -1.3682,  0.6696],\n",
            "        [-0.3037, -0.6224,  1.0533,  0.1342,  2.2085,  0.1197]])\n",
            "Shape: torch.Size([2, 6])  (same rows, doubled columns)\n",
            "\n",
            "Multiple batches:\n",
            "batch1 shape: torch.Size([2, 3])\n",
            "batch2 shape: torch.Size([2, 3])\n",
            "batch3 shape: torch.Size([2, 3])\n",
            "\n",
            "Concatenated batches:\n",
            "Shape: torch.Size([6, 3])  (6 samples, 3 features)\n",
            "\n",
            "Stacked as sequence:\n",
            "Shape: torch.Size([3, 2, 3])  (sequence_length=3, batch_size=2, features=3)\n"
          ]
        }
      ],
      "source": [
        "# Use case 1: Combine feature vectors\n",
        "feature1 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
        "feature2 = torch.tensor([4, 5, 6], dtype=torch.float32)\n",
        "feature3 = torch.tensor([7, 8, 9], dtype=torch.float32)\n",
        "\n",
        "print(\"Feature vectors:\")\n",
        "print(f\"feature1: {feature1}\")\n",
        "print(f\"feature2: {feature2}\")\n",
        "print(f\"feature3: {feature3}\")\n",
        "print()\n",
        "\n",
        "# Stack to create batch\n",
        "batch = torch.stack([feature1, feature2, feature3], dim=0)\n",
        "print(\"Stacked into batch:\")\n",
        "print(batch)\n",
        "print(f\"Shape: {batch.shape}  (batch_size=3, features=3)\")\n",
        "print()\n",
        "\n",
        "# Use case 2: Concatenate layers\n",
        "layer1 = torch.randn(2, 3)\n",
        "layer2 = torch.randn(2, 3)\n",
        "\n",
        "print(\"Layer outputs:\")\n",
        "print(f\"layer1 shape: {layer1.shape}\")\n",
        "print(f\"layer2 shape: {layer2.shape}\")\n",
        "print()\n",
        "\n",
        "# Concatenate features (horizontal)\n",
        "features_concat = torch.cat([layer1, layer2], dim=1)\n",
        "print(\"Concatenated features:\")\n",
        "print(features_concat)\n",
        "print(f\"Shape: {features_concat.shape}  (same rows, doubled columns)\")\n",
        "print()\n",
        "\n",
        "# Use case 3: Stack for batch processing\n",
        "batch1 = torch.randn(2, 3)\n",
        "batch2 = torch.randn(2, 3)\n",
        "batch3 = torch.randn(2, 3)\n",
        "\n",
        "print(\"Multiple batches:\")\n",
        "print(f\"batch1 shape: {batch1.shape}\")\n",
        "print(f\"batch2 shape: {batch2.shape}\")\n",
        "print(f\"batch3 shape: {batch3.shape}\")\n",
        "print()\n",
        "\n",
        "# Stack to create larger batch\n",
        "large_batch = torch.cat([batch1, batch2, batch3], dim=0)\n",
        "print(\"Concatenated batches:\")\n",
        "print(f\"Shape: {large_batch.shape}  (6 samples, 3 features)\")\n",
        "print()\n",
        "\n",
        "# Or stack to create sequence\n",
        "sequence = torch.stack([batch1, batch2, batch3], dim=0)\n",
        "print(\"Stacked as sequence:\")\n",
        "print(f\"Shape: {sequence.shape}  (sequence_length=3, batch_size=2, features=3)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Key Takeaways\n",
        "\n",
        "**Concatenating tensors:**\n",
        "- `torch.cat([t1, t2, ...], dim=d)` - concatenate along dimension d\n",
        "- `torch.stack([t1, t2, ...], dim=d)` - stack along new dimension d\n",
        "\n",
        "**Key differences:**\n",
        "- **cat**: Concatenates along existing dimension (tensors must match except along dim)\n",
        "- **stack**: Creates new dimension and stacks (all tensors must have same shape)\n",
        "\n",
        "**Common use cases:**\n",
        "- **cat**: Combine features, merge batches, concatenate layers\n",
        "- **stack**: Create batch dimension, sequence dimension, stack channels\n",
        "\n",
        "**Remember:** cat expands existing dimension, stack creates new dimension!\n",
        "# Example: y = 2 * x\n",
        "# If x = 1, then y = 2\n",
        "# If x = 2, then y = 4\n",
        "# If x = 3, then y = 6# Example: y = 2 * x\n",
        "# If x = 1, then y = 2\n",
        "# If x = 2, then y = 4\n",
        "# If x = 3, then y = 6# Example: y = 2 * x\n",
        "# If x = 1, then y = 2\n",
        "# If x = 2, then y = 4\n",
        "# If x = 3, then y = 6# Example: y = 2 * x\n",
        "# If x = 1, then y = 2\n",
        "# If x = 2, then y = 4\n",
        "# If x = 3, then y = 6# Example: y = 2 * x\n",
        "# If x = 1, then y = 2\n",
        "# If x = 2, then y = 4\n",
        "# If x = 3, then y = 6# Example: y = 2 * x\n",
        "# If x = 1, then y = 2\n",
        "# If x = 2, then y = 4\n",
        "# If x = 3, then y = 6# Example: y = 2 * x\n",
        "# If x = 1, then y = 2\n",
        "# If x = 2, then y = 4\n",
        "# If x = 3, then y = 6\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example: y = 2 * x\n",
        "# If x = 1, then y = 2\n",
        "# If x = 2, then y = 4\n",
        "# If x = 3, then y = 6asdasdasdasdASDASDASDASDASDASD"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
