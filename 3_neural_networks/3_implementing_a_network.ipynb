{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Implementing a Network from Scratch\n",
        "\n",
        "A neural network is just layers connected together!\n",
        "Output of one layer becomes input to the next layer.\n",
        "Let's build a complete network!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. What is a Neural Network?\n",
        "\n",
        "A neural network is layers stacked together!\n",
        "Input → Layer 1 → Layer 2 → ... → Output\n",
        "Each layer transforms the data into a new representation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reuse Layer class from previous lesson\n",
        "class Layer:\n",
        "    \"\"\"Layer with multiple neurons\"\"\"\n",
        "    \n",
        "    def __init__(self, num_inputs, num_neurons, activation='sigmoid'):\n",
        "        self.weights = torch.randn(num_neurons, num_inputs) * 0.1\n",
        "        self.biases = torch.randn(num_neurons) * 0.1\n",
        "        self.activation_name = activation\n",
        "    \n",
        "    def activate(self, x):\n",
        "        if self.activation_name == 'sigmoid':\n",
        "            return torch.sigmoid(x)\n",
        "        elif self.activation_name == 'relu':\n",
        "            return torch.relu(x)\n",
        "        elif self.activation_name == 'tanh':\n",
        "            return torch.tanh(x)\n",
        "        else:\n",
        "            return x\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        if inputs.dim() == 1:\n",
        "            weighted_sum = inputs @ self.weights.T + self.biases\n",
        "        else:\n",
        "            weighted_sum = inputs @ self.weights.T + self.biases\n",
        "        return self.activate(weighted_sum)\n",
        "\n",
        "# Manual network: 2 layers connected\n",
        "# Input: 2 features\n",
        "# Layer 1: 3 neurons (hidden layer)\n",
        "# Layer 2: 1 neuron (output layer)\n",
        "\n",
        "inputs = torch.tensor([1.0, 2.0])\n",
        "\n",
        "print(\"Neural Network (2 layers):\")\n",
        "print(f\"Input: {inputs}\")\n",
        "print()\n",
        "\n",
        "# Layer 1\n",
        "layer1 = Layer(num_inputs=2, num_neurons=3, activation='sigmoid')\n",
        "hidden_output = layer1.forward(inputs)\n",
        "print(f\"Layer 1 output (3 neurons): {hidden_output}\")\n",
        "print()\n",
        "\n",
        "# Layer 2 (takes Layer 1 output as input)\n",
        "layer2 = Layer(num_inputs=3, num_neurons=1, activation='sigmoid')\n",
        "final_output = layer2.forward(hidden_output)\n",
        "print(f\"Layer 2 output (1 neuron): {final_output}\")\n",
        "print()\n",
        "\n",
        "print(\"Network flow:\")\n",
        "print(f\"Input (2) → Layer 1 (3) → Layer 2 (1) → Output\")\n",
        "print(f\"          {inputs.shape} → {hidden_output.shape} → {final_output.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Neural Network Class from Scratch\n",
        "\n",
        "Let's create a network class that contains multiple layers!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    \"\"\"Neural network from scratch\"\"\"\n",
        "    \n",
        "    def __init__(self, layer_sizes, activations=None):\n",
        "        \"\"\"\n",
        "        layer_sizes: list of layer sizes [input_size, hidden1, hidden2, ..., output_size]\n",
        "        activations: list of activation functions for each layer\n",
        "        \"\"\"\n",
        "        self.layers = []\n",
        "        \n",
        "        # Default to sigmoid for all layers\n",
        "        if activations is None:\n",
        "            activations = ['sigmoid'] * (len(layer_sizes) - 1)\n",
        "        \n",
        "        # Create layers\n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            num_inputs = layer_sizes[i]\n",
        "            num_neurons = layer_sizes[i + 1]\n",
        "            activation = activations[i]\n",
        "            \n",
        "            layer = Layer(num_inputs, num_neurons, activation)\n",
        "            self.layers.append(layer)\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        \"\"\"Forward pass through all layers\"\"\"\n",
        "        x = inputs\n",
        "        \n",
        "        # Pass through each layer sequentially\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x = layer.forward(x)\n",
        "            # Optional: print intermediate outputs\n",
        "            # print(f\"Layer {i+1} output shape: {x.shape}\")\n",
        "        \n",
        "        return x\n",
        "\n",
        "# Create a network: 2 inputs → 3 neurons → 2 neurons → 1 output\n",
        "network = NeuralNetwork(\n",
        "    layer_sizes=[2, 3, 2, 1],\n",
        "    activations=['sigmoid', 'sigmoid', 'sigmoid']\n",
        ")\n",
        "\n",
        "print(\"Neural Network Architecture:\")\n",
        "print(\"Input: 2 features\")\n",
        "print(\"Layer 1: 3 neurons (hidden layer 1)\")\n",
        "print(\"Layer 2: 2 neurons (hidden layer 2)\")\n",
        "print(\"Layer 3: 1 neuron (output layer)\")\n",
        "print()\n",
        "\n",
        "# Test the network\n",
        "inputs = torch.tensor([1.0, 2.0])\n",
        "output = network.forward(inputs)\n",
        "\n",
        "print(f\"Input: {inputs}\")\n",
        "print(f\"Output: {output}\")\n",
        "print()\n",
        "\n",
        "# Show intermediate outputs\n",
        "print(\"Forward pass through network:\")\n",
        "x = inputs\n",
        "for i, layer in enumerate(network.layers):\n",
        "    x = layer.forward(x)\n",
        "    print(f\"After Layer {i+1}: {x} (shape: {x.shape})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Network 1: Simple network (2 → 4 → 1)\n",
        "network1 = NeuralNetwork([2, 4, 1], ['sigmoid', 'sigmoid'])\n",
        "print(\"Network 1: 2 → 4 → 1\")\n",
        "print(f\"Layers: {len(network1.layers)}\")\n",
        "print(f\"Total neurons: 4 + 1 = 5\")\n",
        "print()\n",
        "\n",
        "# Network 2: Deeper network (3 → 5 → 3 → 1)\n",
        "network2 = NeuralNetwork([3, 5, 3, 1], ['sigmoid', 'sigmoid', 'sigmoid'])\n",
        "print(\"Network 2: 3 → 5 → 3 → 1\")\n",
        "print(f\"Layers: {len(network2.layers)}\")\n",
        "print(f\"Total neurons: 5 + 3 + 1 = 9\")\n",
        "print()\n",
        "\n",
        "# Network 3: Wide network (2 → 10 → 1)\n",
        "network3 = NeuralNetwork([2, 10, 1], ['relu', 'sigmoid'])\n",
        "print(\"Network 3: 2 → 10 → 1 (ReLU hidden, sigmoid output)\")\n",
        "print(f\"Layers: {len(network3.layers)}\")\n",
        "print(f\"Total neurons: 10 + 1 = 11\")\n",
        "print()\n",
        "\n",
        "# Test all networks with same input\n",
        "test_input = torch.tensor([1.0, 2.0])\n",
        "\n",
        "print(\"Testing networks with input = [1.0, 2.0]:\")\n",
        "print(f\"Network 1 output: {network1.forward(test_input):.4f}\")\n",
        "print(f\"Network 2 output: {network2.forward(test_input[:2]):.4f}\")  # First 2 elements\n",
        "print(f\"Network 3 output: {network3.forward(test_input):.4f}\")\n",
        "\n",
        "# Count total parameters\n",
        "def count_parameters(network):\n",
        "    total = 0\n",
        "    for layer in network.layers:\n",
        "        total += layer.weights.numel() + layer.biases.numel()\n",
        "    return total\n",
        "\n",
        "print(\"\\nTotal parameters (weights + biases):\")\n",
        "print(f\"Network 1: {count_parameters(network1)}\")\n",
        "print(f\"Network 2: {count_parameters(network2)}\")\n",
        "print(f\"Network 3: {count_parameters(network3)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Batch Processing with Networks\n",
        "\n",
        "Networks can process batches of inputs efficiently!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a network\n",
        "network = NeuralNetwork([2, 4, 1], ['sigmoid', 'sigmoid'])\n",
        "\n",
        "# Single input\n",
        "single_input = torch.tensor([1.0, 2.0])\n",
        "single_output = network.forward(single_input)\n",
        "\n",
        "print(\"Single input:\")\n",
        "print(f\"Input: {single_input}\")\n",
        "print(f\"Output: {single_output}\")\n",
        "print()\n",
        "\n",
        "# Batch of inputs (4 samples)\n",
        "batch_inputs = torch.tensor([[1.0, 2.0],\n",
        "                             [3.0, 4.0],\n",
        "                             [5.0, 6.0],\n",
        "                             [7.0, 8.0]])\n",
        "\n",
        "batch_outputs = network.forward(batch_inputs)\n",
        "\n",
        "print(\"Batch of inputs:\")\n",
        "print(f\"Input shape: {batch_inputs.shape} (batch_size=4, features=2)\")\n",
        "print(f\"Input:\\n{batch_inputs}\")\n",
        "print()\n",
        "print(f\"Output shape: {batch_outputs.shape} (batch_size=4, outputs=1)\")\n",
        "print(f\"Outputs:\\n{batch_outputs}\")\n",
        "print()\n",
        "\n",
        "print(\"Notice: Network processes entire batch at once!\")\n",
        "print(\"This is much faster than processing one at a time.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Key Takeaways\n",
        "\n",
        "**What a neural network is:**\n",
        "- Multiple layers connected together\n",
        "- Output of one layer = input to next layer\n",
        "- Transforms inputs through multiple representations\n",
        "\n",
        "**Network architecture:**\n",
        "- Input layer: receives data\n",
        "- Hidden layers: transform data (can have many!)\n",
        "- Output layer: produces final prediction\n",
        "\n",
        "**Key concepts:**\n",
        "- **Depth**: Number of layers (more layers = deeper network)\n",
        "- **Width**: Number of neurons per layer (more neurons = wider network)\n",
        "- **Forward pass**: Data flows from input → output\n",
        "\n",
        "**Forward pass:**\n",
        "1. Input goes to first layer\n",
        "2. Each layer's output becomes next layer's input\n",
        "3. Final layer produces network output\n",
        "\n",
        "**Remember:** Networks learn complex patterns by stacking simple transformations!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
